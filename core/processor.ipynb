{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0006d707-34cb-42b3-98f1-a58ce398519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3904190-6102-40c8-914e-7bad17bf5487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53708de2-f638-4c3e-bd5f-51e5cf597f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687ca10d-1723-4cba-b6e7-e99a6d6ecab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13bc1c19-7d2c-4b89-831d-3b91730c5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9627e60-273d-4857-b8b8-3b86c8cab526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "230f01cf-9250-47b8-9d54-22c198ce30ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(frame):\n",
    "    # converting to grayscale\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv.equalizeHist(frame_gray)\n",
    "\n",
    "    face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    # detecting faces\n",
    "    faces = face_cascade.detectMultiScale(frame_gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    frame_faces = []\n",
    "    for (x, y, w, d) in faces:\n",
    "        frame_faces.append(frame[x: x+w, y: y+d])\n",
    "\n",
    "    return frame_faces, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a8405f-fc34-44ae-a261-f2447da478d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(frame, model):\n",
    "    embeddings = model(frame)\n",
    "    return embeddings.numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63cebb9a-988f-4c16-833a-65de7c7ec7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_processed(directory, model):\n",
    "    \n",
    "    # Function to get all files from the directory\n",
    "    def get_list():\n",
    "        return [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "    paths = get_list()  # Get all file paths in the directory\n",
    "\n",
    "    tags = {}  # Dictionary to hold image file names and corresponding features\n",
    "    dataset = []  # List to hold all feature vectors\n",
    "\n",
    "    for path in paths:\n",
    "        com_path = os.path.join(directory, path)  # Complete path to the file\n",
    "        image = cv.imread(com_path)  # Read the image\n",
    "\n",
    "        frame_faces, faces = get_face(image)  # Get faces and face regions from the image\n",
    "        \n",
    "        tags[path] = 0  # Initialize the list for the current image\n",
    "\n",
    "        for f in frame_faces:\n",
    "            # Extract features for the current face\n",
    "            features = get_features(f, model).tolist()\n",
    "            tags[path] += 1  # Store features in tags\n",
    "            dataset.append(features)  # Store features in the dataset\n",
    "\n",
    "    return tags, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a5abc82-4ff5-4b1d-9028-372985a97adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(dataset, tags, max_clusters=20, threshold=0.01):\n",
    "    X = numpy.array(dataset)\n",
    "\n",
    "    best_kmean=None\n",
    "    n=2\n",
    "    max_score=-1\n",
    "    for i in range(n, max_clusters+1):\n",
    "        kmean = KMeans(n_clusters=i)\n",
    "        labels = kmean.fit_predict(X)\n",
    "        score = silhouette_score(X, labels)\n",
    "        prev_score = -1\n",
    "\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            n = i\n",
    "            best_kmean = kmean\n",
    "        # early stopping\n",
    "        if abs(score - prev_score) < threshold:\n",
    "            break\n",
    "\n",
    "        prev_score = score\n",
    "\n",
    "    \n",
    "    labels_list = best_kmeans.labels_.tolist()\n",
    "    tagged = {}\n",
    "    track = 0\n",
    "    for i, num_faces in tags.items():\n",
    "        tagged[i] = []\n",
    "        for j in range(track, track+num_faces):\n",
    "            tagged.append(labels_list[j])\n",
    "        track += num_faces\n",
    "\n",
    "    return tagged, n, best_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ee733-f604-483d-928a-6ec64ba2c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_doubt(kmean, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
